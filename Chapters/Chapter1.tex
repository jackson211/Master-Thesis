\chapter{Introduction}

Large volumes of data have been collected and generated considerably over the recent years, among the increasing popularity of smartphones and Internet services. Multidimensional data such as geographic coordinates data and CAD data is considered as core infrastructure and component in the technology world \cite{gunther1990research, morton1966computer, kriegel2003using}. Data queries in spatial data, such as range query and k nearest neighbour query has been widely used in map based products and location based services. Google maps use range queries and KNN to find points of interest. For example, finding restaurants in a region and finding restaurants near me. In VLSI CAD, spatial data index is also used to manage two-dimensional data objects such as polylines and polygons \cite{liu1994evaluation}. In some other areas, the spatial management system is also integrated with image processing and computer vision. For example, medical images and remote sensing images use spatial databases to store and location spatial objects from the images \cite{borah2004improved, adhikary1996knowledge, mantel2004matching, tagare1997medical}. 

How to effectively manage spatial data have been studied significantly in the past few decades \cite{Gaede:1998fp, ooi1990efficient}. Spatial index methods have been developed in many different approaches. Some have derived from a one-dimensional approach, such as linear hashing \cite{larson1980linear} and extendible hashing \cite{fagin1979extendible}. Some have derived from popular one-dimensional B-Tree structure \cite{Bayer:2002ds}, such as K-D-Tree \cite{Bentley:1975gn}, Quad-Tree \cite{CSUR:tm}, R-Tree \cite{Guttman:1984ka}, and so on. All spatial indexes support two-dimensional data points, and most indexes are also capable of handling polygons or line segments. Spatial queries are also different from regular database queries, range query and KNN query is especially important, and each index has a unique way to process these query tasks. 



\section{Motivation}
A recent study on the learned index \cite{Kraska:2017vh} demonstrates that a learned cumulative distribution function (CDF) from a data distribution can predict the position of the key, and invented the Recursive Model Index (RMI). Traditional data indexes follow certain policies to store data in the data structure, and they have to consider all data distribution. There are several advantages to a learned index. Firstly, the learned CDF could potentially reduce the search time complexity, especially in some cases where the CDF curve is perfectly fitted according to the dataset. Secondly, the memory size for a learned model is much smaller than the traditional data structure. For example, B-Tree stores data items in the nodes, the size of a data item must be taken into the memory size, whereas a learned B-Tree model is trying to find the page that contains the query item. The memory size of a learned model contains few parameters. Thirdly, a learned neural network can utilize the SIMD capabilities of CPU and GPU, and this can be a significant advantage on a large scale dataset \cite{patterson2016computer}. All the advantages of the learned model open up a new field in databases, the power behind the learned function that describe the data distribution can be applied to many other data structures and algorithms, and potentially make the traditional data structures and algorithms more efficient. 

Furthermore, the one-dimensional learned index can be expanded to handle two-dimensional data. ZM index \cite{Wang:2019ks} uses the Z-order curve to connect two-dimensional data points in space transformed into one-dimensional data, then it is easy to apply the learned index model upon the one-dimensional data. The Flood \cite{Nathan:2019wc} uses a grid layout partitioning the space into different cells, then during the querying phase, the search window looks for intersecting cells, then refine and filter the query result from the cells. The RSMI \cite{Qi:2020uz} combines ideas from RMI, Z-order curve and R-Tree, and it uses Z-order numbering each partitioning block, then uses RMI to predict the corresponding block id. There are many more learned spatial indexes that integrate the traditional method with ideas from the learned index. All the learned spatial indexes have shown some performance gain or memory size reduction that benefits from the learned model. Therefore, introducing the learned model in the traditional spatial data index can further improve the efficiency of the spatial data management system. 



\section{Research Questions}
There are two primary aims of this proposed research: 
\begin{itemize}
\item Investigating the existing spatial indexes, the learned indexes and novel learned spatial indexes.
\item To apply the learned model technique based on existing knowledge about data indexes. 
\end{itemize}

The success achieved in the one-dimensional data index raises a question if we are reasoning about a similar task on multidimensional data: how can we improve the efficiency of a spatial data index through learned models? Specifically, can we improve the performance of the index by reducing the query lookup speed; or reducing the memory consumption; and compare to existing approaches to the learned spatial index, can we do better or worse than those methods? 


\section{Approach and Outcomes}

The objectives of this research are to investigate existing data indexes and propose a learned index method that supports spatial queries. The main contribution of the study consist of three parts:
\begin{itemize}
    \item We reviewed previous work on various data indexes, including traditional spatial indexes, one-dimensional learned indexes, and learned spatial indexes.
    \item We proposed a new spatial index method: Learned Spatial Hashmap (LSPH). The LSPH is a spatial index that is built on top of a hashmap with a learned hash function.  
    \item We validated the LSPH with real-world and synthetic datasets, and performance is competitive against other spatial indexes.
\end{itemize}

Previous studies on the learned spatial indexes have focused on combining traditional spatial index methods with the learned CDF. Almost every learned spatial index has claimed to have a faster search time and less memory size compared to the traditional methods. However, there are some disadvantages to those methods. First, most learned spatial indexes tended to focus on efficiency rather than accuracy, many of them predict the index position from a recursive model index, which the prediction result can not guarantee to locate the correct approximate position since the error can be very different from the maximum error bounds. Although the error can be reduced to an acceptable range, it still requires hyperparameter tuning for a single application.  Second, many of the existing methods lack support for spatial queries. The ZM index does not support KNN queries \cite{Wang:2019ks}. Flood and Tsunami process a range scan for query points, but they also do not support KNN query \cite{Nathan:2019wc, Ding:2020we}. Third, learned indexes that use a multilayer neural network can have an expensive build time. 

We proposed the Learned Spatial Hashmap (LSPH), which is a hashmap with a learned hash function for handling spatial queries. This method is straightforward, it uses values of one dimension from a two-dimensional data pair to train a monotonic CDF that describes the data distribution along one dimension in a set of spatial objects.  The learned CDF is functioning as the hash function for the hashmap, and the predicted value from the learned CDF used as the hash value. Since the hash value from the CDF is going to be the same regardless of prediction error, it guarantees to locate the same spot and obtain the search result according to the query. We are also introduced to the single-dimensional index building, which is to train the CDF model with values that are from one dimension. The benefits of building indexes with the dimension with a larger variance are 
\begin{enumerate*}
  \item Increasing the space utilization in the hashmap.
  \item Query performance gain.
  \item Solving skewness by choosing the dimension is less skewed.
\end{enumerate*}
There are three types of spatial query supported by the LSPH: point quey, range query and KNN query. In addition to handling spatial points, the LSPH is also supporting a minimum bounding box. Therefore, the LSPH manages spatial data efficiently and addresses some disadvantages of existing learned indexes. 

Evaluation is measured from three aspects: memory consumption, build time, point query time, and accuracy of the result. LSPH has obtained better or even performance results compared to other methods under certain conditions. Overall, LSPH is balanced between query performance, memory consumption and building performance, and it guarantees to retrieve query results 100\% accurately. Compared to other index methods, LSPH achieves up to $8\times$ query performance speedup over R-Tree and $40\times$ speedup over a ZM index on a real-world dataset while maintaining similar memory consumption with R-Tree.  




\section{Thesis Structure}
This thesis comprises 5 chapters in total, including this introduction. The rest of the chapters are organized as follows. 
\begin{itemize}
    \item Chapter 2 reviewed numerous traditional index methods targeting spatial objects, novel one-dimensional learned indexes, and learned multidimensional indexes. 

    \item Chapter 3 introduces our proposed Learned Spatial Hashmap (LSPH) and discusses the index design, properties of the learned hashmap, and spatial query handling in detail. 

    \item Chapter 4 provides an overview of experiments and compares the performance results of LSPH with the other two indexes on both real-world and synthetic datasets. 

    \item Chapter 5 summarizes our study, and addresses some limitations and provides future research considerations. 

\end{itemize}